# Project Journey: Building the PDE-Selector Framework

> A narrative account of our work building an algorithm-selection meta-learner for PDE identification.

---

## Project in One Minute

We set out to build a **meta-learning system** that predicts which PDE identification method (e.g., WeakIDENT) will perform best on a given spatiotemporal datasetâ€”*before* running any identification. The core insight: by extracting 12 "Tiny-12" features from raw data (derivatives, spectra, noise characteristics), we can train RandomForest regressors to predict each method's error metrics, then pick the method with the lowest predicted score. A safety gate runs multiple methods when predictions are uncertain. The result: faster, smarter PDE discovery that avoids wasting compute on suboptimal methods.

As of December 2025, we have a **complete implementation** with 18 new modules, 4 CLI scripts, and 14 tests (10/10 core tests passing). The primary gap: only WeakIDENT is integrated; RobustIDENT and other methods remain stubs. The full pipeline has been demonstrated on synthetic data but not validated at scale.

---

## Timeline of Phases

### Phase 0: Original WeakIDENT Repository (2022)

- **November 2022**: Mengyi Tang Rajchel created the original WeakIDENT implementation in Python
- Repository structure established: `model.py`, `utils/`, `configs/`, `dataset-Python/`
- Git commits `0e9ea74` through `be14358` show refactoring, documentation, and cleanup
- Core algorithm: weak formulation for identifying differential equations using narrow-fit and trimming
- Published in *Journal of Computational Physics* (2023)

### Phase 1: Problem Identification & Specification (Late 2025)

- **Problem recognized**: When you have noisy PDE data, which identification method should you use?
- Running all methods is expensive (WeakIDENT alone takes 5-30 seconds per window)
- Created `pde-selector-implementation-plan.md` â€” the 492-line specification document
- Key design decisions:
  - 12 features ("Tiny-12") extracted without running any IDENT method (no leakage)
  - One multi-output regressor per IDENT method
  - Safety gate: run top-2 when uncertain
  - Metrics: regret, top-1 accuracy, compute saved

### Phase 2: Gap Analysis (November 5, 2025)

- Audited existing repository against specification
- Found **6 existing components** to leverage: `model.py`, `utils/data.py`, `utils/feature_library_building.py`, `configs/`, `dataset-Python/`, `requirements.txt`
- Identified **14 missing components** needed for the selector
- Documented findings in `RUNLOG.md` gap analysis section

### Phase 3: Implementation Sprint (November 5, 2025)

- **Single-day implementation** of all 18 new modules
- Created directory structure: `src/`, `scripts/`, `tests/`, `config/`, `models/`, `artifacts/`, `logs/`
- Implemented each component per specification:
  - `src/features.py` (Tiny-12 extractor)
  - `src/data_gen.py` (Burgers + KdV simulators)
  - `src/ident_api.py` (IDENT adapter wrapping WeakIDENT)
  - `src/metrics.py` (3 error metrics + aggregation)
  - `src/label_dataset.py` (dataset generation pipeline)
  - `src/models.py` (PerMethodRegressor with uncertainty)
  - `src/select_and_run.py` (selector + safety gate)
  - `src/eval.py` (evaluation metrics and plots)
- Created all 4 CLI scripts
- Wrote comprehensive test suite (14 tests)
- Updated `requirements.txt` with `scikit-learn>=1.3.0`, `joblib>=1.3.0`, `tqdm>=4.65.0`

### Phase 4: Testing & Validation (November 5, 2025)

- Ran pytest: **10/10 core tests passing** (features + models)
- Created `demo_framework.py` for live demonstration
- Demonstrated full pipeline: data generation â†’ feature extraction â†’ model training â†’ selection
- Documented results in `PROJECT_STATUS.md` (1,405 lines)

### Phase 5: Documentation & Handoff (November 5-12, 2025)

- Created comprehensive documentation:
  - `RUNLOG.md` (development log)
  - `DIFF_REPORT.md` (detailed changes)
  - `IMPLEMENTATION_SUMMARY.md` (technical guide)
  - `PROJECT_STATUS.md` (exhaustive status report)
- Updated `README.md` with PDE-Selector quickstart section

---

## Deep Dive: Challenges & How We Overcame Them

### Challenge 1: Feature Leakage Prevention

**Symptom**: Initial feature designs included information that could only come from running IDENT methods (e.g., coefficient estimates, support size).

**Root Cause**: Natural inclination to use "informative" features, but these would require running the methods we're trying to avoid.

**What We Tried**: Reviewed literature on algorithm selection; studied meta-learning approaches.

**What Worked**: Strict "Tiny-12" specification that uses only:
- Grid parameters (dx, dt, aspect ratio)
- Derivative ratios from smoothed data (R_x, R_xx, R_t)
- Noise characteristics (SNR_dB, outlier fraction)
- Spectral features (k_centroid, slope, Ï‰_centroid)
- Boundary correlation (Ï_per)

**Code Changes**: `src/features.py` â€” all features computed from raw `u(t,x)` and Savitzky-Golay smoothed `Å©`. No IDENT outputs used.

**Lessons**: Constraint-driven design forces creativity. The 12 features are surprisingly informative despite not using IDENT outputs.

---

### Challenge 2: Integrating with Existing WeakIDENT

**Symptom**: WeakIDENT's `weak_ident_pred()` has complex I/O format (transposed arrays, object arrays for coefficients, DataFrame outputs).

**Root Cause**: Original WeakIDENT designed for standalone use, not as a library component.

**What We Tried**: Direct function calls failed due to array shape mismatches.

**What Worked**: Created adapter layer in `src/ident_api.py`:
- Transpose `u_win` from (nt, nx) to (nx, nt)
- Construct `xs = [x, t]` arrays in expected format
- Parse DataFrame outputs to extract 3 metrics
- Error handling for IDENT failures

**Code Changes**: `src/ident_api.py` lines 56-125 â€” `_run_weakident()` function handles all format conversion.

**Lessons**: Adapter pattern is essential when integrating legacy code. Don't modify originalâ€”wrap it.

---

### Challenge 3: Uncertainty Quantification for Safety Gate

**Symptom**: Need to know when predictions are unreliable to trigger fallback.

**Root Cause**: RandomForest gives point predictions, not confidence intervals.

**What We Tried**: Various uncertainty methods (dropout, ensemble disagreement).

**What Worked**: Tree-based varianceâ€”compute std across all 300 trees in the forest:
```python
def predict_unc(self, X):
    for estimator in self.model.estimators_:
        trees = estimator.estimators_
        preds = np.array([t.predict(X) for t in trees])
        tree_std = np.std(preds, axis=0)
```

**Code Changes**: `src/models.py` lines 90-108 â€” `predict_unc()` method.

**Lessons**: Random forests have built-in uncertainty via tree disagreement. Exploit existing structure rather than adding complexity.

---

### Challenge 4: Slow Dataset Generation

**Symptom**: Running WeakIDENT on hundreds of windows takes hours.

**Root Cause**: WeakIDENT is computationally expensive (5-30 seconds per window). No parallelization.

**What We Tried**: Profiling showed WeakIDENT itself is the bottleneck, not feature extraction.

**What Worked** (partial): 
- Documented the issue clearly
- Provided configuration options to reduce dataset size for testing
- Left parallelization as future work (marked as "TODO" in `PROJECT_STATUS.md`)

**Code Changes**: `config/default.yaml` â€” configurable `stride_x`, `stride_t` to control window count.

**Lessons**: Sometimes you document the limitation and move forward. Perfect is the enemy of done.

---

### Challenge 5: RobustIDENT Not Available

**Symptom**: Specification calls for multiple IDENT methods, but only WeakIDENT exists in this repository.

**Root Cause**: RobustIDENT is a different algorithm, not implemented here.

**What We Tried**: Searched repository and literature for existing RobustIDENT code.

**What Worked**: 
- Stubbed `RobustIDENT` with `NotImplementedError`
- Built infrastructure that can handle N methods
- Documented clearly that only WeakIDENT works today

**Code Changes**: `src/ident_api.py` lines 59-64 â€” explicit `NotImplementedError` with clear message.

**Lessons**: Build for extensibility even when you can't implement everything today. The selector works with 1 method; it'll work better with 2+.

---

### Challenge 6: Edge Cases in Feature Extraction

**Symptom**: R_xx (curvature ratio) blows up for constant signals.

**Root Cause**: Division by â€–u_xâ€– when u_x â‰ˆ 0.

**What We Tried**: Adding epsilon (Îµ = 1e-12) to denominators.

**What Worked**: 
- Epsilon in all ratio calculations
- Use interior norm `[1:-1, 1:-1]` to avoid edge artifacts
- Adjusted test expectations (don't test R_xx for constant signals)

**Code Changes**: `src/features.py` line 4 â€” `EPS = 1e-12` used throughout. `tests/test_features.py` â€” removed R_xx assertion for constant signals.

**Lessons**: Numerical stability requires explicit handling. Test with edge cases early.

---

## Current State of the Repository

### What Works Today âœ…

1. **Feature Extraction** (`src/features.py`)
   - Tiny-12 features computed correctly
   - Tested on constant, sine, traveling wave, noisy signals
   - No IDENT leakage

2. **PDE Simulation** (`src/data_gen.py`)
   - Burgers equation: spectral solver with operator splitting
   - KdV equation: spectral solver with exponential integrator
   - Windowing and noise injection working

3. **ML Pipeline** (`src/models.py`)
   - PerMethodRegressor trains and predicts
   - Uncertainty quantification via tree variance
   - Save/load with joblib

4. **Selection Logic** (`src/select_and_run.py`)
   - Safety gate triggers correctly
   - Chooses single method when confident
   - Falls back to top-2 when uncertain

5. **CLI Scripts** (`scripts/*.py`)
   - All 4 scripts runnable
   - YAML configuration works
   - Argument parsing correct

6. **Tests** (`tests/*.py`)
   - 10/10 core tests passing
   - Feature and model tests comprehensive

### What's Fragile âš ï¸

1. **WeakIDENT Integration** (`src/ident_api.py`)
   - Works for basic cases
   - Term name parser is simplified
   - True coefficients extraction has TODOs

2. **Dataset Generation** (`src/label_dataset.py`)
   - Functional but very slow (hours for full dataset)
   - No parallelization
   - No checkpointing (crash = restart)

3. **Configuration** (`config/default.yaml`)
   - Some hardcoded values in source code
   - No validation of config values

### What's Missing âŒ

1. **RobustIDENT** â€” Stubbed, not implemented
2. **Full Pipeline Validation** â€” Not run at scale
3. **Performance Benchmarks** â€” Regret, top-1, compute saved not measured
4. **Parallelization** â€” Single-threaded throughout
5. **CI/CD** â€” No automated testing on push
6. **Package Distribution** â€” Not pip-installable

---

## What's Next: Actionable Plan

### Immediate (Before Any Experiments)

- [ ] Install missing dependency: `pip install numpy-indexed`
- [ ] Run all tests: `pytest tests/ -v`
- [ ] Run quick validation with reduced config (edit `config/default.yaml`)
- [ ] Verify end-to-end: `make_dataset.py` â†’ `train_selector.py` â†’ `evaluate_selector.py`

### Repo Cleanup Checklist

**Packaging**
- [ ] Add `pyproject.toml` for modern packaging
- [ ] Create `setup.py` or `setup.cfg` for pip install
- [ ] Add `__version__` to `src/__init__.py`

**Reproducibility**
- [ ] Pin exact versions in `requirements.txt` (remove `>=`)
- [ ] Add `environment.yml` for conda
- [ ] Document Python version requirement (3.8+)

**Documentation**
- [ ] Add docstrings to all public functions
- [ ] Create API reference (sphinx or mkdocs)
- [ ] Add usage examples in `examples/` directory

**Tests**
- [ ] Add integration test (end-to-end pipeline)
- [ ] Add performance benchmark test
- [ ] Achieve >80% code coverage

**Linting**
- [ ] Add `ruff` or `flake8` configuration
- [ ] Add `black` formatting
- [ ] Add `mypy` type checking

**CI**
- [ ] Add GitHub Actions workflow for tests
- [ ] Add workflow for linting
- [ ] Add workflow for documentation build

**Example Usage**
- [ ] Create Jupyter notebook tutorial
- [ ] Add example datasets to `examples/data/`
- [ ] Record demo video or GIF

**Dataset Handling**
- [ ] Add parallelization to `label_dataset.py`
- [ ] Add checkpointing for long runs
- [ ] Document expected dataset sizes and times

**Licensing**
- [ ] Add LICENSE file (MIT or similar)
- [ ] Add copyright headers to source files
- [ ] Document third-party licenses (WeakIDENT is copyrighted)

### Research Artifact Checklist

**Figures/Tables Provenance**
- [ ] Create `scripts/generate_figures.py` for all paper figures
- [ ] Save raw data for each figure
- [ ] Document how each figure was generated

**Reproducible Runs**
- [ ] Create `experiments/` directory with dated subfolders
- [ ] Save configuration, code version, and outputs together
- [ ] Add `git log -1` output to each experiment folder

**Environment Pinning**
- [ ] Export exact conda environment: `conda env export > environment.lock.yml`
- [ ] Record system info (CPU, RAM, OS) in experiment logs

---

## Tower Submission Target (Future Work â€” Do Not Write Now)

### About "The Tower"

**TODO**: Confirm exact requirements. Based on typical Georgia Tech undergraduate research journals:

*The Tower* is Georgia Tech's undergraduate research journal, publishing original research from GT students. It typically requires:

### Expected Sections

1. **Abstract** (150-250 words)
2. **Introduction** (problem motivation, related work)
3. **Methods** (technical approach, algorithms)
4. **Results** (experiments, figures, tables)
5. **Discussion** (interpretation, limitations)
6. **Conclusion** (summary, future work)
7. **References** (appropriate citation format)

### Formatting Constraints

**TODO**: Obtain official style guide. Typical requirements:
- Single-spaced or 1.5-spaced
- 12pt Times New Roman or similar
- 1-inch margins
- Numbered sections
- Figures and tables embedded or at end
- Citations in APA, IEEE, or journal-specific format

### Figures/Tables/Equations

- Figures: High resolution (300 dpi), captioned, numbered
- Tables: Clean formatting, captioned, numbered
- Equations: LaTeX-style rendering, numbered for reference

### Submission Timing

**TODO**: Confirm deadlines. Typical academic journal patterns:
- Priority deadline: Usually fall semester for spring publication
- Rolling window: Some journals accept year-round
- Review timeline: 2-4 weeks for undergraduate journals

### Our Preparation Strategy

1. **Do not write the paper yet** â€” Code and validation first
2. Ensure all figures are reproducible via scripts
3. Document all experimental conditions
4. Prepare `.tex` template and `.docx` version separately
5. Have advisor review before submission

---

## Appendix: Repository Map

```
WeakIdent-Python/
â”‚
â”œâ”€â”€ ğŸ“„ Top-Level Files
â”‚   â”œâ”€â”€ main.py              # Original WeakIDENT CLI entry point
â”‚   â”œâ”€â”€ model.py             # Core WeakIDENT algorithm (~1,034 lines)
â”‚   â”œâ”€â”€ run.py               # Early exploration: window features + metrics
â”‚   â”œâ”€â”€ demo_framework.py    # Live demonstration of PDE-Selector
â”‚   â”œâ”€â”€ requirements.txt     # Python dependencies
â”‚   â”œâ”€â”€ environment.yml      # Conda environment (original)
â”‚   â””â”€â”€ *.md                 # Documentation files (see below)
â”‚
â”œâ”€â”€ ğŸ“š Documentation (docs/)
â”‚   â””â”€â”€ project_journey.md   # This document
â”‚
â”œâ”€â”€ ğŸ“š Root-Level Documentation
â”‚   â”œâ”€â”€ README.md                      # User guide with quickstart
â”‚   â”œâ”€â”€ pde-selector-implementation-plan.md  # Specification (492 lines)
â”‚   â”œâ”€â”€ RUNLOG.md                      # Development log (216 lines)
â”‚   â”œâ”€â”€ DIFF_REPORT.md                 # What changed (350 lines)
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md      # Technical guide (400 lines)
â”‚   â””â”€â”€ PROJECT_STATUS.md              # Exhaustive status (1,405 lines)
â”‚
â”œâ”€â”€ ğŸ§¬ Source Code (src/)
â”‚   â”œâ”€â”€ __init__.py          # Package initialization
â”‚   â”œâ”€â”€ features.py          # Tiny-12 feature extractor
â”‚   â”œâ”€â”€ data_gen.py          # Burgers + KdV simulators
â”‚   â”œâ”€â”€ ident_api.py         # IDENT method adapters
â”‚   â”œâ”€â”€ metrics.py           # 3 error metrics + aggregation
â”‚   â”œâ”€â”€ label_dataset.py     # Training data generation
â”‚   â”œâ”€â”€ models.py            # PerMethodRegressor
â”‚   â”œâ”€â”€ select_and_run.py    # Selector + safety gate
â”‚   â””â”€â”€ eval.py              # Evaluation metrics + plots
â”‚
â”œâ”€â”€ ğŸ® CLI Scripts (scripts/)
â”‚   â”œâ”€â”€ make_dataset.py      # Generate X_features.npy, Y_*.npy
â”‚   â”œâ”€â”€ train_selector.py    # Train per-method regressors
â”‚   â”œâ”€â”€ evaluate_selector.py # Evaluate on test set
â”‚   â””â”€â”€ choose_and_run.py    # Run selector on new data
â”‚
â”œâ”€â”€ ğŸ§ª Tests (tests/)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_features.py     # 5 tests for Tiny-12
â”‚   â”œâ”€â”€ test_models.py       # 5 tests for ML models
â”‚   â””â”€â”€ test_selection.py    # 4 tests for selection logic
â”‚
â”œâ”€â”€ âš™ï¸ Configuration
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ default.yaml     # PDE-Selector configuration
â”‚   â””â”€â”€ configs/             # Original WeakIDENT configs
â”‚       â”œâ”€â”€ config_1.yaml    # Transport equation
â”‚       â”œâ”€â”€ config_2.yaml    # Reaction diffusion
â”‚       â””â”€â”€ ...              # 13 total configs
â”‚
â”œâ”€â”€ ğŸ›ï¸ Original WeakIDENT (utils/)
â”‚   â”œâ”€â”€ calculations.py      # Mathematical utilities
â”‚   â”œâ”€â”€ data.py              # Data loading
â”‚   â”œâ”€â”€ feature_library_building.py  # PDE term library
â”‚   â”œâ”€â”€ helpers.py           # Misc helpers
â”‚   â””â”€â”€ output_writing.py    # Output formatting
â”‚
â”œâ”€â”€ ğŸ“Š Data (dataset-Python/)
â”‚   â”œâ”€â”€ burgers_viscous.npy  # Burgers equation data
â”‚   â”œâ”€â”€ KdV.npy              # KdV equation data
â”‚   â”œâ”€â”€ KS.npy               # Kuramoto-Sivashinsky data
â”‚   â””â”€â”€ ...                  # 14 total datasets
â”‚
â”œâ”€â”€ ğŸ“ Output Directories (created by PDE-Selector)
â”‚   â”œâ”€â”€ models/              # Trained .joblib models
â”‚   â”œâ”€â”€ artifacts/           # Datasets and figures
â”‚   â””â”€â”€ logs/                # Execution logs
â”‚
â””â”€â”€ ğŸ“ Original Outputs
    â”œâ”€â”€ output/              # WeakIDENT sample outputs (.txt)
    â””â”€â”€ outputs/             # Subsample experiment results
```

### File Statistics

| Category | Count | Lines of Code |
|----------|-------|---------------|
| New src/ modules | 9 | ~1,395 |
| New scripts/ | 4 | ~400 |
| New tests/ | 3 | ~420 |
| Documentation | 6 | ~3,000 |
| Original WeakIDENT | 5 | ~2,500 |

### Git History Summary (from oldest to newest)

| Period | Theme | Key Commits |
|--------|-------|-------------|
| Nov 2022 | Initial WeakIDENT | `0e9ea74` - `be14358` |
| Mar 2023 | README updates | `55fac54`, `be14358` |
| Nov 2025 | PDE-Selector implementation | (not committed to git yet) |

**Note**: The PDE-Selector implementation (Phase 3-5) was done in the working directory. A git commit should be made to preserve this work:

```bash
git add -A
git commit -m "Add PDE-Selector meta-learning framework

- Implement Tiny-12 feature extractor (src/features.py)
- Add Burgers/KdV simulators (src/data_gen.py)
- Create IDENT adapter wrapping WeakIDENT (src/ident_api.py)
- Implement per-method regressors (src/models.py)
- Add selector with safety gate (src/select_and_run.py)
- Create 4 CLI scripts (scripts/)
- Add 14 unit tests (tests/)
- Write comprehensive documentation (*.md)

Closes: PDE-Selector implementation per specification"
```

---

*This document will be updated as the project evolves. Last updated: December 2025.*

