# Figure Manifest

> Maps each figure to its file path, generation script, and the claim it supports.

---

## Figure 1: Confusion Matrix

| Attribute | Value |
|-----------|-------|
| **File Path** | `data/figures/confusion_matrix.png` |
| **Generated By** | `scripts/generate_figures.py` → `plot_confusion_matrix()` |
| **Description** | Heatmap showing predicted vs. true best method labels on the test split |
| **Claim Supported** | Random Forest correctly predicts best method with 97% accuracy; misclassifications are primarily between LASSO and STLSQ |

---

## Figure 2: Feature Importance

| Attribute | Value |
|-----------|-------|
| **File Path** | `data/figures/feature_importance.png` |
| **Generated By** | `scripts/generate_figures.py` → `plot_feature_importance()` |
| **Description** | Horizontal bar chart ranking the 12 Tiny-12 features by Random Forest importance |
| **Claim Supported** | u_xx std (23.2%), u_xxx std (16.2%), and u_x std (11.5%) are most predictive; derivative-based features dominate |

---

## Figure 3: Regret CDF

| Attribute | Value |
|-----------|-------|
| **File Path** | `data/figures/regret_cdf.png` |
| **Generated By** | `scripts/generate_figures.py` → `plot_regret_cdf()` |
| **Description** | Cumulative distribution function of selector regret (difference between selector's e2 and oracle's e2) |
| **Claim Supported** | 99.4% of windows have zero regret; selector matches oracle performance in most cases |
| **Note** | This was computed on FULL dataset (training-inclusive); held-out evaluation recommended |

---

## Figure 4: Model Comparison

| Attribute | Value |
|-----------|-------|
| **File Path** | `data/figures/model_comparison.png` |
| **Generated By** | `scripts/generate_figures.py` → `plot_model_comparison()` |
| **Description** | Grouped bar chart comparing test accuracy and 5-fold CV accuracy across 6 ML classifiers |
| **Claim Supported** | Random Forest achieves highest test accuracy (97.06%); Gradient Boosting and KNN also perform well (>95%) |

---

## Figure 5: Method Distribution

| Attribute | Value |
|-----------|-------|
| **File Path** | `data/figures/method_distribution.png` |
| **Generated By** | `scripts/generate_figures.py` → `plot_best_method_distribution()` |
| **Description** | Pie chart showing distribution of "best method" labels across the dataset |
| **Claim Supported** | LASSO (63%) and STLSQ (37%) dominate; WeakIDENT and RobustIDENT rarely win on clean synthetic data |
| **Limitation Noted** | Distribution skew means naive baseline achieves 63%; however, selector still provides +34pp improvement |

---

## Figure Generation Command

```bash
# Generate all figures
docker compose run --rm weakident python scripts/generate_figures.py

# Or locally (if dependencies installed)
python scripts/generate_figures.py
```

Figures are saved to `data/figures/` at 300 DPI resolution.
